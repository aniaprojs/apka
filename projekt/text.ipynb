{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ania/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stepped', 'ramen', 'restaurant', 'savory', 'culinary', 'every', 'bowls', 'noodles', 'could', 'work', 'bowl', 'array', 'promising', 'journey', 'rich', 'flavors', 'chashu', 'pork', 'eggs', 'soul', 'come', 'last', 'face', 'broth', 'world', 'melted', 'away', 'new', 'simple', 'many']\n",
      "savory past door restaurant\n",
      " I breathed in deeply, allowing the steam to caress my face before diving in with eager anticipation.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"\"\"\n",
    "As I stepped through the door of the ramen restaurant, a wave of savory aromas enveloped me, instantly tantalizing my taste buds and stirring memories of past culinary adventures. The ambiance was cozy yet bustling, with diners nestled into every available nook, their chopsticks dancing eagerly over steaming bowls of noodles.\n",
    "\n",
    "I found myself drawn to a seat at the counter, where I could watch the masterful chefs at work, their hands a blur of motion as they expertly crafted each bowl with precision and care. The menu offered a dizzying array of options, from classic tonkotsu to innovative fusion creations, each promising a journey through the rich tapestry of Japanese flavors.\n",
    "\n",
    "After much deliberation, I settled on the house special: a hearty miso ramen adorned with slices of tender chashu pork, perfectly soft-boiled eggs, and an array of vibrant vegetables. As I waited for my order, I sipped on a cup of fragrant green tea, letting its warmth soothe my soul and prepare my palate for the feast to come.\n",
    "\n",
    "At last, the moment arrived, and my bowl of ramen was placed before me, a work of art in its own right. I breathed in deeply, allowing the steam to caress my face before diving in with eager anticipation. The first slurp was pure bliss, the noodles silky smooth and the broth rich and complex, each mouthful a symphony of flavors and textures that danced across my tongue.\n",
    "\n",
    "With each bite, I felt myself transported to another world, a world where every worry melted away in the face of culinary perfection. The chashu pork practically melted in my mouth, its savory juices mingling with the umami goodness of the broth, while the eggs added a creamy richness that elevated the dish to new heights.\n",
    "\n",
    "As I savored every last drop, I couldn't help but marvel at the magic of ramen â€“ how such simple ingredients could come together to create something so transcendent, so utterly satisfying. It was more than just a meal; it was an experience, a journey of the senses that left me feeling nourished in body and soul.\n",
    "\n",
    "As I reluctantly pushed my empty bowl away, I knew that this would not be my last visit to the ramen restaurant. There were still so many flavors to explore, so many bowls to savor, each one promising a new adventure in culinary delight. And as I stepped back out into the world, belly full and heart happy, I carried with me the memory of that perfect bowl of ramen, a reminder of the simple joys that make life truly worth living.\n",
    "\"\"\"\n",
    "\n",
    "def generate_title_from_keywords(keywords, text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Extract nouns and adjectives from the text\n",
    "    nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
    "    adjectives = [token.text for token in doc if token.pos_ == \"ADJ\"]\n",
    "    \n",
    "    # Construct a sentence using the extracted nouns and adjectives\n",
    "    if adjectives and nouns:\n",
    "        title = \" \".join(adjectives[:2]) + \" \" + \" \".join(nouns[:2])\n",
    "    elif nouns:\n",
    "        title = \" \".join(nouns[:2])\n",
    "    else:\n",
    "        title = \" \".join(adjectives[:2])\n",
    "    print(title)\n",
    "    # return title.capitalize() + \".\"\n",
    "\n",
    "stopWords = set(stopwords.words(\"english\")) \n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Creating a frequency table to keep the  \n",
    "# score of each word    \n",
    "freqTable = dict() \n",
    "for word in words: \n",
    "    word = word.lower() \n",
    "    if word in stopWords: \n",
    "        continue\n",
    "    if word in freqTable: \n",
    "        freqTable[word] += 1\n",
    "    else: \n",
    "        freqTable[word] = 1\n",
    "\n",
    "title_words = [word for word, freq in freqTable.items() if freq > 1 and len(word) > 2]\n",
    "print(title_words)\n",
    "\n",
    "generate_title_from_keywords(title_words, text)\n",
    "\n",
    "# Creating a dictionary to keep the score \n",
    "# of each sentence \n",
    "sentences = sent_tokenize(text) \n",
    "sentenceValue = dict() \n",
    "   \n",
    "for sentence in sentences: \n",
    "    for word, freq in freqTable.items(): \n",
    "        if word in sentence.lower(): \n",
    "            if sentence in sentenceValue: \n",
    "                sentenceValue[sentence] += freq\n",
    "            else: \n",
    "                sentenceValue[sentence] = freq \n",
    "   \n",
    "sumValues = 0\n",
    "for sentence in sentenceValue: \n",
    "    sumValues += sentenceValue[sentence] \n",
    "   \n",
    "# Average value of a sentence from the original text \n",
    "average = int(sumValues / len(sentenceValue)) \n",
    "   \n",
    "# Storing sentences into our summary. \n",
    "summary = ''\n",
    "summary_length = 0\n",
    "for sentence in sentences:\n",
    "    if summary_length > 2:\n",
    "        break\n",
    "    if len(sentence.split(' ')) < 20:\n",
    "        summary += \" \" + sentence \n",
    "        summary_length += 1\n",
    "print(summary) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
